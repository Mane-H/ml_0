{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b48f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, method='sgd', lr=0.1):\n",
    "        \"\"\"\n",
    "        :param method: 'sgd' for SGD, 'gd' for GD, 'analytic' for analytic solution\n",
    "        \"param lr: learning rate\n",
    "        \"\"\"\n",
    "        self._lr = lr\n",
    "\n",
    "        if method not in ('analytic', 'gd', 'sgd'):\n",
    "            raise ValueError('method can be only \"gd\", \"sgd\" or \"analytic\"')\n",
    "\n",
    "        self._method = method\n",
    "        self._x = None\n",
    "        self._y = None\n",
    "\n",
    "    def loss_function(self):\n",
    "        y_hat=self._x@self._b\n",
    "        L=0\n",
    "        if len(self._x)!=len(self._y):\n",
    "            raise ValueError(\"vector dimensions should be same\")        \n",
    "        for i in range(0,len(y_hat)):\n",
    "            L+=(y[i]-y_hat[i])**2\n",
    "            return L\n",
    "        if self._x is None or self._y is None:\n",
    "            raise ValueError('All methods can be called after fit method is called.')\n",
    "\n",
    "    def gradient(self, x, y):\n",
    "        grad=np.array()\n",
    "        grad_intercept=-2*np.sum(y-x@b)\n",
    "        if x.shape[1]==2:\n",
    "            grad_x=-2*np.sum(x@(y-x@b))\n",
    "            grad=np.append(grad_x)\n",
    "        elif x.shape[1]>2:\n",
    "            for i in range (0, x.shape[1]):\n",
    "                grad_i=-2*np.sum(x[i]@(y-x[i]@b))\n",
    "                grad=np.append(grad_i)        \n",
    "        return grad\n",
    "        \"\"\"\n",
    "        Calculate the gradient of the loss function.\n",
    "        If x is a vector, calculate only for this data (for SGD), else for whole dataset (for GD)\n",
    "        \"\"\"\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        TODO: normalize the data and fit the linear regression.\n",
    "        :param x: features matrix\n",
    "        :param y: labels\n",
    "        :returns: None if can't fit, weights, if fitted.\n",
    "        \"\"\"\n",
    "        self._weights = np.randn(x.shape[1]+1)\n",
    "        ones=np.array(x.shape[0]**0)\n",
    "        self._x = np.append(ones, x, axis=[1])\n",
    "        self._y = y\n",
    "\n",
    "        if self._method == 'sgd':\n",
    "            for i in range(0, x.shape[0]):\n",
    "                self._weights=self._weights-lamb*self.gradient(self._x, y)\n",
    "            pass\n",
    "        elif self._method == 'gd':\n",
    "            lamb=0.01\n",
    "            for i in range (0,1000):\n",
    "                self._weights=self._weights-lamb*self.gradient(self._x,y)\n",
    "                pass\n",
    "        elif self._method == 'analytic':\n",
    "            self._weights = np.linalg.inv(x.T@x)@x.T@y\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('method can be only \"gd\", \"sgd\" or \"analytic\"')\n",
    "\n",
    "        return self._weights\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        TODO: Calculate the predictions for each data in features matrix.\n",
    "        :param x: features matrix\n",
    "        \"\"\"\n",
    "        y=x@self.weights\n",
    "        \n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
